{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Nd65WZy_goa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOVfxmn7c5yn"
   },
   "source": [
    "## **Raw Code for Pulling Tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VdwMPRo-c7bZ",
    "outputId": "05c7541e-c922-4c74-f2a2-74a75dceba84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter endpoint name: endpoint2\n",
      "endpointURL_In_Use: https://api.twitter.com/2/tweets/search/all\n",
      "APICredentials: C:\\Users\\niina\\OneDrive - The University of Texas-Rio Grande Valley\\Twitter Data Collection Workshop Folder\\TwitterDataCollectionWorkshop\\APICredentials.json\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpyqo6ro3xwetdqz0xryzdy8ykp2m5\n",
      "Start Date:  2022-03-01T00:00:00.000Z\n",
      "End Date:  2022-03-24T23:59:59.000Z\n",
      "# of Tweets added from this response:  499\n",
      "Total # of Tweets added:  499\n",
      "2022-03-25 11:50:57\n",
      "-------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c16decd3c890>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m     \u001b[0mendpoint2_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-c16decd3c890>\u001b[0m in \u001b[0;36mendpoint2_main\u001b[1;34m()\u001b[0m\n\u001b[0;32m    289\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y-%m-%d %H:%M:%S\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocaltime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m                         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m                 \u001b[1;31m# If no next token exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#pip install csvkit\n",
    "#pip install jsonlines\n",
    "import requests  # For sending GET requests from the API\n",
    "import os  # For saving access tokens and for file management when creating and adding to the dataset\n",
    "import json # For dealing with json responses we receive from the API\n",
    "#import jsonlines\n",
    "import pandas as pd #using pandas dataframe for data handling\n",
    "import csv # For saving the response data in CSV format\n",
    "import datetime # For parsing the dates received from twitter in readable formats\n",
    "import dateutil.parser\n",
    "import unicodedata\n",
    "import time #To add wait time between requests\n",
    "from time import gmtime, strftime, localtime # For current time\n",
    "from config.pathDefinitions import ROOT_DIR #for handling relative paths\n",
    "\n",
    "#from dataAppendFormats.appendCSV import append_to_csv\n",
    "#from dataAppendFormats import appendJSON\n",
    "#from main_program import endpoint2_main\n",
    "#from main_program import create_headers\n",
    "\n",
    "#APIpath ='C:/Users/niina/OneDrive - The University of Texas-Rio Grande Valley/Twitter Data Collection Workshop Folder/TwitterDataCollectionWorkshop/' #'./gdrive/My Drive/'\n",
    "#APIpath = os.path.realpath(os.path.join(os.path.dirname(__file__), '..', , 'mydata.json')))\n",
    "#print(\"working directory: \" \"{}\".format(os.getcwd()))\n",
    "\n",
    "APIpath = os.path.join(ROOT_DIR, 'APICredentials.json')\n",
    "APICredentials = json.loads(open(APIpath).read())  \n",
    "bearer_token = APICredentials['bearer_token']\n",
    "endpoint2 = APICredentials[input(\"Enter endpoint name: \")]\n",
    "print(\"endpointURL_In_Use: \"\"{}\".format(endpoint2))\n",
    "print(\"APICredentials: \" \"{}\".format(APIpath))\n",
    "\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def create_url(keyword, start_date, end_date, max_results = 10):\n",
    "    search_url = endpoint2 \n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'query': keyword,\n",
    "                    'start_time': start_date,\n",
    "                    'end_time': end_date,\n",
    "                    'max_results': max_results,\n",
    "                    'expansions': 'author_id,in_reply_to_user_id,geo.place_id', \n",
    "                    'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,entities,referenced_tweets,reply_settings,source',\n",
    "                    'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n",
    "                    'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
    "                    'next_token': {}}\n",
    "    return (search_url, query_params)\n",
    "\n",
    "  \n",
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    params['next_token'] = next_token   #params object received from create_url function\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
    "    if response.status_code != 200:\n",
    "        time.sleep(15)\n",
    "        try:\n",
    "            return connect_to_endpoint(url, headers, params, next_token = next_token)\n",
    "        except Exception:\n",
    "            raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def append_to_csv(json_response, fileName):\n",
    "\n",
    "    #A counter variable\n",
    "    counter = 0\n",
    "\n",
    "    #Open OR create the target CSV file\n",
    "    csvFile = open(fileName, \"a\", newline=\"\", encoding='utf-8')\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "\n",
    "\n",
    "    #for user in json_response['data']:\n",
    "        #follower_count = user['public_metrics']\n",
    "        #print(follower_count)\n",
    "      \n",
    "\n",
    "    #Loop through each tweet\n",
    "    for tweet in json_response['data']:\n",
    "        \n",
    "        # We will create a variable for each since some of the keys might not exist for some tweets\n",
    "        # So we will account for that\n",
    "\n",
    "        # 1. Author ID\n",
    "        try: #if('author_id' in tweet):\n",
    "            author_id = tweet['author_id']\n",
    "        except KeyError: #else:\n",
    "            author_id = \" \"\n",
    "        \n",
    "        # 2. Time created\n",
    "        try: #if ('created_at' in tweet):\n",
    "            created_at = dateutil.parser.parse(tweet['created_at'])\n",
    "        except: #else: \n",
    "            created_at = \" \"\n",
    "\n",
    "        # 3. Geolocation\n",
    "        try:   \n",
    "            geo = tweet['geo']['place_id']\n",
    "            #geo = tweet['geo']['coordinates']['coordinates']\n",
    "        except KeyError:\n",
    "            geo = \" \"\n",
    "\n",
    "        # 4. Tweet ID\n",
    "        try: #if('id' in tweet):\n",
    "            tweet_id = tweet['id']\n",
    "        except KeyError: #else:\n",
    "            tweet_id = \" \"\n",
    "\n",
    "        # 5. Language\n",
    "        try: #if('lang' in tweet):\n",
    "            lang = tweet['lang']\n",
    "        except KeyError: #else: \n",
    "            lang = \" \"\n",
    "\n",
    "        # 6. Tweet metrics\n",
    "        #impression_count = tweet['non_public_metrics']['impression_count']\n",
    "        #user_profile_clicks= ['non_public_metrics']['user_profile_clicks']\n",
    "\n",
    "        if('public_metrics' in tweet) and 'retweet_count' in (tweet['public_metrics']):\n",
    "            retweet_count = tweet['public_metrics']['retweet_count']\n",
    "        else: retweet_count = \" \"\n",
    "\n",
    "        #organic_retweet_count = tweet['organic_metrics']['retweet_count']\n",
    "\n",
    "        if('public_metrics' in tweet) and 'reply_count' in (tweet['public_metrics']):\n",
    "            reply_count = tweet['public_metrics']['reply_count']\n",
    "        else: reply_count = \" \"\n",
    "\n",
    "\n",
    "        #organic_reply_count = tweet['organic_metrics']['reply_count']\n",
    "\n",
    "\n",
    "        if('public_metrics' in tweet) and 'like_count' in (tweet['public_metrics']):\n",
    "            like_count = tweet['public_metrics']['like_count']\n",
    "        else: like_count = \" \"\n",
    "\n",
    "\n",
    "        #organic_like_count = tweet['organic_metrics']['like_count']\n",
    "\n",
    "\n",
    "        if('public_metrics' in tweet) and 'quote_count' in (tweet['public_metrics']):\n",
    "            quote_count = tweet['public_metrics']['quote_count']\n",
    "        quote_count = \" \"\n",
    "\n",
    "        \n",
    "        if ('entities' in tweet) and 'hashtags' in (tweet['entities']):\n",
    "            hashtags = tweet['entities']['hashtags'][0]['tag']\n",
    "        else:\n",
    "            hashtags = \" \"\n",
    "\n",
    "\n",
    "        if ('entities' in tweet) and 'cashtags' in (tweet['entities']):\n",
    "            cashtags = tweet['entities']['cashtags'][0]['tag']\n",
    "        else:\n",
    "            cashtags = \" \"\n",
    "\n",
    "        #print(cashtags)\n",
    "\n",
    "        #PM1 = tweet['author_id'][0]\n",
    "        #PM2 = tweet['author_id'][1]\n",
    "        #PM3 = tweet['author_id'][2]\n",
    "        #PM4 = tweet['author_id'][3]\n",
    "        #PM5 = tweet['author_id'][4]\n",
    "        #PM6 = tweet['author_id'][5]\n",
    "        #PM7 = tweet['author_id'][6]\n",
    "\n",
    "        # 7. source\n",
    "        try: #if('source' in tweet):\n",
    "            source = tweet['source']\n",
    "        except: #else: \n",
    "            source = \" \"\n",
    "        \n",
    "\n",
    "        # 8. Tweet text\n",
    "        try: #if('text' in tweet):\n",
    "            text = tweet['text']\n",
    "        except: #else: \n",
    "            text = \" \"\n",
    "\n",
    "        #\n",
    "        try: #if('conversation_id' in tweet):\n",
    "            conversation_id = tweet['conversation_id']\n",
    "        except: #else: \n",
    "            conversation_id = \" \"\n",
    "            \n",
    "\n",
    "        # Assemble all data in a list\n",
    "        #res = [author_id, created_at, geo, tweet_id, lang, like_count, organic_like_count, quote_count, reply_count, organic_reply_count, retweet_count, organic_retweet_count, source, text, conversation_id]\n",
    "        res = [author_id, created_at, geo, tweet_id, lang, like_count, quote_count, reply_count, retweet_count, source, text, conversation_id, hashtags, cashtags]\n",
    "\n",
    "        # Append the result to the CSV file\n",
    "        csvWriter.writerow(res)\n",
    "        counter += 1\n",
    "\n",
    "    # When done, close the CSV file\n",
    "    csvFile.close()\n",
    "\n",
    "    # Print the number of tweets for this iteration\n",
    "    print(\"# of Tweets added from this response: \", counter) \n",
    "\n",
    "def endpoint2_main():\n",
    "    try:\n",
    "        #Inputs for the request\n",
    "        #bearer_token = auth()\n",
    "        headers = create_headers(bearer_token)\n",
    "        keyword = \"(from:bitcoin OR Bitcoins OR $BTC OR XBT OR #XBT OR $XBT OR BTCTN OR #bitcoin OR #BTC OR (Bitcoin cryptocurrency) OR satoshi) lang:en -is:retweet\"\n",
    "        #keyword = \"(from:ethereum OR #ethereum OR #Ethereum OR Ethereum OR #ETH OR (Ethereum cryptocurrency)) lang:en -is:retweet\"\n",
    "        #start_time = \"2015-01-01T00:00:00.000Z\"\n",
    "        #end_time = \"2015-01-31T00:00:00.000Z\"\n",
    "\n",
    "        start_list =[#'2022-01-01T00:00:00.000Z',\n",
    "                    #'2022-02-01T00:00:00.000Z',\n",
    "                    '2022-03-01T00:00:00.000Z',\n",
    "                    #'2022-04-01T00:00:00.000Z',\n",
    "                    #'2022-05-01T00:00:00.000Z',\n",
    "                    #'2022-06-01T00:00:00.000Z',\n",
    "                    #'2022-07-01T00:00:00.000Z',\n",
    "                    #'2022-08-01T00:00:00.000Z',\n",
    "                    #'2022-09-01T00:00:00.000Z',\n",
    "                    #'2022-10-01T00:00:00.000Z',\n",
    "                    #2022-11-01T00:00:00.000Z',\n",
    "                    #2022-12-01T00:00:00.000Z'\n",
    "                    ]\n",
    "\n",
    "        end_list =  [#'2022-01-31T23:59:59.000Z',\n",
    "                    #'2022-02-28T23:59:59.000Z',\n",
    "                    '2022-03-24T23:59:59.000Z',\n",
    "                    #'2022-04-30T23:59:59.000Z',\n",
    "                    #'2022-05-31T23:59:59.000Z',\n",
    "                    #'2022-06-30T23:59:59.000Z',\n",
    "                    #'2022-07-31T23:59:59.000Z',\n",
    "                    #'2022-08-31T23:59:59.000Z',\n",
    "                    #'2022-09-30T23:59:59.000Z',\n",
    "                    #'2022-10-31T23:59:59.000Z',\n",
    "                    #'2022-11-30T23:59:59.000Z',\n",
    "                    #'2022-12-31T23:59:59.000Z'\n",
    "                    ] \n",
    "\n",
    "        max_results = 500\n",
    "\n",
    "        #Total number of tweets we collected from the loop\n",
    "        total_tweets = 0\n",
    "        \n",
    "        DataPath = \"dataExploring2022.csv\" \n",
    "        # Create file\n",
    "        csvFile = open(DataPath, \"a\", newline=\"\", encoding='utf-8')\n",
    "        csvWriter = csv.writer(csvFile)\n",
    "\n",
    "        #Create headers for the data you want to save, in this example, we only want save these columns in our dataset\n",
    "        csvWriter.writerow(['author_id', 'created_at', 'geo', 'tweet_id','lang', 'like_count', 'quote_count', 'reply_count','retweet_count', 'source','tweet','conversation_id', 'hashtags', 'cashtags'])\n",
    "        csvFile.close()\n",
    "\n",
    "        #next_token = ''\n",
    "        next_token = None\n",
    "\n",
    "        for i in range(0,len(start_list)):\n",
    "\n",
    "            # Inputs\n",
    "            count = 0 # Counting tweets per time period\n",
    "            max_count = 50000000 #Max tweets per time period\n",
    "            flag = True\n",
    "\n",
    "            # Check if flag is true\n",
    "            while flag:\n",
    "                # Check if max_count reached\n",
    "                if count >= max_count:\n",
    "                    break\n",
    "                print(\"-------------------\")\n",
    "                print(\"Token: \", next_token)\n",
    "                url = create_url(keyword, start_list[i],end_list[i], max_results)\n",
    "                json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "                result_count = json_response['meta']['result_count']\n",
    "\n",
    "                if 'next_token' in json_response['meta']:\n",
    "                    # Save the token to use for next call\n",
    "                    next_token = json_response['meta']['next_token']\n",
    "                    print(\"Next Token: \", next_token)\n",
    "                    if result_count is not None and result_count > 0 and next_token is not None:\n",
    "                        print(\"Start Date: \", start_list[i])\n",
    "                        print(\"End Date: \", end_list[i])\n",
    "                        append_to_csv(json_response, DataPath)\n",
    "                        count += result_count\n",
    "                        total_tweets += result_count\n",
    "                        print(\"Total # of Tweets added: \", total_tweets)\n",
    "                        #print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))   \n",
    "                        print(strftime(\"%Y-%m-%d %H:%M:%S\", localtime()))                                                                                    \n",
    "                        print(\"-------------------\")\n",
    "                        time.sleep(5)                \n",
    "                # If no next token exists\n",
    "                else:\n",
    "                    if result_count is not None and result_count > 0:\n",
    "                        print(\"-------------------\")\n",
    "                        print(\"Start Date: \", start_list[i])\n",
    "                        append_to_csv(json_response, DataPath)\n",
    "                        count += result_count\n",
    "                        total_tweets += result_count\n",
    "                        print(\"Total # of Tweets added: \", total_tweets)\n",
    "                        print(\"No Next token exists-------------------\")\n",
    "                        time.sleep(5)\n",
    "                    \n",
    "                    #Since this is the final request, turn flag to false to move to the next time period.\n",
    "                    flag = False\n",
    "                    next_token = None\n",
    "                time.sleep(5)\n",
    "        print(\"Total number of results: \", total_tweets)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    finally:\n",
    "\n",
    "        #Saving to Google Drive #Method 2 \n",
    "        #df = pd.read_csv('data.csv',engine='python', error_bad_lines=False)\n",
    "        #df = df[0].str.split(',', expand=True)\n",
    "        #df.to_csv('data_Complete.csv')\n",
    "        pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    endpoint2_main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.read_csv(\"dataExploring2022.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>geo</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>tweet</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>cashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>author_id</td>\n",
       "      <td>created_at</td>\n",
       "      <td>geo</td>\n",
       "      <td>tweet_id</td>\n",
       "      <td>lang</td>\n",
       "      <td>like_count</td>\n",
       "      <td>quote_count</td>\n",
       "      <td>reply_count</td>\n",
       "      <td>retweet_count</td>\n",
       "      <td>source</td>\n",
       "      <td>tweet</td>\n",
       "      <td>conversation_id</td>\n",
       "      <td>hashtags</td>\n",
       "      <td>cashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1474790183102935044</td>\n",
       "      <td>2022-03-24 23:59:58+00:00</td>\n",
       "      <td></td>\n",
       "      <td>1507145229194854429</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>XRP is getting ready to take off to the moon! ...</td>\n",
       "      <td>1507145229194854429</td>\n",
       "      <td>altcoin</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1470894299961339909</td>\n",
       "      <td>2022-03-24 23:59:58+00:00</td>\n",
       "      <td></td>\n",
       "      <td>1507145226338680839</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>MINT YOUR APE NOW!!🔥\\n\\nMint Price 0.05 ETH🔥\\n...</td>\n",
       "      <td>1507145226338680839</td>\n",
       "      <td>nfts</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338491577803689984</td>\n",
       "      <td>2022-03-24 23:59:57+00:00</td>\n",
       "      <td></td>\n",
       "      <td>1507145224652529665</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>25/03/2022 00:00:02: XBT Bitmex Trollbox stats...</td>\n",
       "      <td>1507145224652529665</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>503518603</td>\n",
       "      <td>2022-03-24 23:59:57+00:00</td>\n",
       "      <td></td>\n",
       "      <td>1507145223167610882</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>We just know #XRP will moon #crypto #binance #...</td>\n",
       "      <td>1507145223167610882</td>\n",
       "      <td>XRP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1471900055682568196</td>\n",
       "      <td>2022-03-24 23:59:57+00:00</td>\n",
       "      <td></td>\n",
       "      <td>1507145222878285828</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>MINT YOUR APE NOW!!🔥\\n\\nMint Price 0.05 ETH🔥\\n...</td>\n",
       "      <td>1507145222878285828</td>\n",
       "      <td>nfts</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1502196699443433475</td>\n",
       "      <td>2022-03-24 23:59:56+00:00</td>\n",
       "      <td></td>\n",
       "      <td>1507145221062148099</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>TRUSTWALLET \\nIs giving out $ETH, $BTC, $TWT, ...</td>\n",
       "      <td>1507145221062148099</td>\n",
       "      <td></td>\n",
       "      <td>ETH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1233788712594673664</td>\n",
       "      <td>2022-03-24 23:59:56+00:00</td>\n",
       "      <td></td>\n",
       "      <td>1507145220294680588</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>MINT YOUR APE NOW!!🔥\\n\\nMint Price 0.05 ETH🔥\\n...</td>\n",
       "      <td>1507145220294680588</td>\n",
       "      <td>nfts</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2281314234</td>\n",
       "      <td>2022-03-24 23:59:56+00:00</td>\n",
       "      <td></td>\n",
       "      <td>1507145219455787008</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>bitcoinagile</td>\n",
       "      <td>Axie Infinity (AXS) price reverses course with...</td>\n",
       "      <td>1507145219455787008</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1479247787258785795</td>\n",
       "      <td>2022-03-24 23:59:56+00:00</td>\n",
       "      <td></td>\n",
       "      <td>1507145219036352517</td>\n",
       "      <td>en</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1/ 🚨🗳️Vote for PHUNCHKINS S2 now by RT + Likin...</td>\n",
       "      <td>1507145219036352517</td>\n",
       "      <td>PHUNCHKINS</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                 created_at  geo             tweet_id  \\\n",
       "0            author_id                 created_at  geo             tweet_id   \n",
       "1  1474790183102935044  2022-03-24 23:59:58+00:00       1507145229194854429   \n",
       "2  1470894299961339909  2022-03-24 23:59:58+00:00       1507145226338680839   \n",
       "3  1338491577803689984  2022-03-24 23:59:57+00:00       1507145224652529665   \n",
       "4            503518603  2022-03-24 23:59:57+00:00       1507145223167610882   \n",
       "5  1471900055682568196  2022-03-24 23:59:57+00:00       1507145222878285828   \n",
       "6  1502196699443433475  2022-03-24 23:59:56+00:00       1507145221062148099   \n",
       "7  1233788712594673664  2022-03-24 23:59:56+00:00       1507145220294680588   \n",
       "8           2281314234  2022-03-24 23:59:56+00:00       1507145219455787008   \n",
       "9  1479247787258785795  2022-03-24 23:59:56+00:00       1507145219036352517   \n",
       "\n",
       "   lang  like_count  quote_count  reply_count  retweet_count           source  \\\n",
       "0  lang  like_count  quote_count  reply_count  retweet_count           source   \n",
       "1    en           0                         0              0  Twitter Web App   \n",
       "2    en           0                         0              0  Twitter Web App   \n",
       "3    en           0                         0              0          Twitter   \n",
       "4    en           0                         0              0  Twitter Web App   \n",
       "5    en           0                         0              0  Twitter Web App   \n",
       "6    en           1                         2              0  Twitter Web App   \n",
       "7    en           0                         0              0  Twitter Web App   \n",
       "8    en           0                         1              0     bitcoinagile   \n",
       "9    en          12                         4              9  Twitter Web App   \n",
       "\n",
       "                                               tweet      conversation_id  \\\n",
       "0                                              tweet      conversation_id   \n",
       "1  XRP is getting ready to take off to the moon! ...  1507145229194854429   \n",
       "2  MINT YOUR APE NOW!!🔥\\n\\nMint Price 0.05 ETH🔥\\n...  1507145226338680839   \n",
       "3  25/03/2022 00:00:02: XBT Bitmex Trollbox stats...  1507145224652529665   \n",
       "4  We just know #XRP will moon #crypto #binance #...  1507145223167610882   \n",
       "5  MINT YOUR APE NOW!!🔥\\n\\nMint Price 0.05 ETH🔥\\n...  1507145222878285828   \n",
       "6  TRUSTWALLET \\nIs giving out $ETH, $BTC, $TWT, ...  1507145221062148099   \n",
       "7  MINT YOUR APE NOW!!🔥\\n\\nMint Price 0.05 ETH🔥\\n...  1507145220294680588   \n",
       "8  Axie Infinity (AXS) price reverses course with...  1507145219455787008   \n",
       "9  1/ 🚨🗳️Vote for PHUNCHKINS S2 now by RT + Likin...  1507145219036352517   \n",
       "\n",
       "     hashtags  cashtags  \n",
       "0    hashtags  cashtags  \n",
       "1     altcoin            \n",
       "2        nfts            \n",
       "3                        \n",
       "4         XRP            \n",
       "5        nfts            \n",
       "6                   ETH  \n",
       "7        nfts            \n",
       "8     Bitcoin            \n",
       "9  PHUNCHKINS            "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17004 entries, 0 to 17003\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   author_id        17004 non-null  object\n",
      " 1   created_at       17004 non-null  object\n",
      " 2   geo              17004 non-null  object\n",
      " 3   tweet_id         17004 non-null  object\n",
      " 4   lang             17004 non-null  object\n",
      " 5   like_count       17004 non-null  object\n",
      " 6   quote_count      17004 non-null  object\n",
      " 7   reply_count      17004 non-null  object\n",
      " 8   retweet_count    17004 non-null  object\n",
      " 9   source           17004 non-null  object\n",
      " 10  tweet            17004 non-null  object\n",
      " 11  conversation_id  17004 non-null  object\n",
      " 12  hashtags         17004 non-null  object\n",
      " 13  cashtags         17004 non-null  object\n",
      "dtypes: object(14)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNJr2nrkU+d9VgUZ/AeI5QM",
   "collapsed_sections": [
    "QU8G8RWncXR8"
   ],
   "mount_file_id": "1KlktelzQypSU21UYRFRLveX3KauffXYx",
   "name": "BitcoinCryptoSentiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
